## 注意点  
- 未解析、获取文本前，输出结果仍为不可读代码


## 所需知识


### 1、正则表达式
- 下载网页，设置后特定的正则表达式，通过re的findall方法抓取信息
- 结果输出为字典的形式，也可以输出特定的信息
- 缺点：不稳定，网页容易发生改变，且正则表达式复杂

1、定位元素

- re的search()、findall()、match()等方法

2、解析元素、获取文本：方法groups()


### 2、BeatifulSoup
1、生成soup文档，处理格式不完整的html代码，使其完善，如补全元素标签等
```
soup = BeatifulSoup(broken_html, 'html.parse'/'html5lib')
```

2、定位元素
- find()方法，只定位第一个元素
- find_all方法，定位所有的元素，并输出为列表

3、解析元素、获取文本：pprint模块
- 格式化/美化数据结构，此处的作用为输出格式化的fixed_html
```
from pprint import pprint
pprint(fixed_html)
```

4、缺点：速度很慢，纯python编写


### 3、 Lxml 
1、解析html、美化html 
```
from Lxml import fromstring, tostring
tree = fromstring(broken_html)  
print(tree)
fixed_html = tostring(tree, pretty_print=True)
```

2、定位元素（1）：CSS选择器  
　  [CSS教程链接](https://www.w3school.com.cn/cssref/css_selectors.asp)
　  返回值为整个匹配的带标签的值

3、定位元素（2）：XPath选择器

作用 | XPath选择器|CSS选择器
---|---|---
选择所有链接                            |'//a'                               | 'a'
选择类名为"main"的 div 元素             |'//div[@class="main"]'              | 'div.main'
选择 ID 为"list"的 ul 元素              |'//ul[@id="list"]'                  |'ul#list'
从所有段落中选择文本                    |'//p/text()'                        |'p'*
选择所有类名中包含'test'的 div 元素     |'//div[contains(@class, 'test')]'   | 'div [class*="test"]'
选择所有包含链接或列表的 div 元素       | '//div[a\|ul] '                    | 'div a, div ul'
选择 href 属性中包含 google.com 的链接  |'//a[contains(@href, "google.com")] |'a'*

4、解析元素、获取文本：方法text_content()

5、查看家族树
- 允许查看家族树中的父元素、上一个兄弟元素、下一个兄弟元素、子元素、所有子元素