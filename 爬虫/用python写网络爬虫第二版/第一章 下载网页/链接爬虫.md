## 思想  
- 通过初始URL，迭代遍历其中的子链接，顺序存入seen变量，弹出最后一个URL，并进行下载，再访问其子链接，如此递归遍历所有URL。
- 同时判断URL是否已下载过，设置子链接深度，设置代理，设置下载延时以防被墙


## 所需知识  
### 1、urllib的parse模块  
用于解析URL、拼接URL  
```
link = urljoin(start_url, path)  
```
- path可为相对路径（不带/或//）、根路径（/）绝对路径（//）


### 2、Python的set()方法  
创建不重复集合  
eg: a.set(attrition)
- a.add(attrition)当作整体添加
- a.update(attrition)拆分字符串后添加
- a.remove(attrition)移除


### 3、urllob的robotsparser模块
检测robots.txt文件，判断代理是否可用

```
rp = robotparser.RobotFileParser()
rp.set_url('URL/robots.txt')
rp.read()
rp.can_fetch(user_agent, url)  #返回值为TRUE/FALSE
```


### 4、time模块
自带延时功能
- time.time()返回当前时间戳，自1970年起
- time.delay(n)停止程序进程n秒